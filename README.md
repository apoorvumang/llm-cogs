# llm-cogs

# BERTScore prediction dataset

We selected around 6500 text samples from various sources such as bigpatent, samsum, wiki bio datasets. Each data point in this dataset was annotated with BERTScore, taking GPT-3.5-Turbo's summaries as the reference gold standard. In this case, our cascade of models consisted of Text-Davinci-003, Text-Curie-001, and Vicuna-13b-1.2. Each line in the jsonl is a json format string. It consists of the context, gold_summary(generated by GPT-3.5), and summary which contains the candidate summaries, and scores which contains scores of those candidate summaries (in order: davinci, curie and vicuna).
